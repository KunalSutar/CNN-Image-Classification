{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb07124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88188674",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c951aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='C:\\\\Users\\\\kunal\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset,mnist_info = tfds.load(name='mnist',with_info=True,as_supervised=True) \n",
    "mnist_info\n",
    "\n",
    "#readt the below output carefully, we will extract a lot of values from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03de78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf50b0",
   "metadata": {},
   "source": [
    "#### Now getting number of vbalidation samlpes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55aaa97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=6000>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_validation_samples = 0.1* mnist_info.splits['train'].num_examples #this will hold the number of validation samples\n",
    "#Since this value could be a float, we will convert it to tf.int64\n",
    "\n",
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64)\n",
    "num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc3279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=10000>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly storing the number of test samples.\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples #this will hold the number of validation samples\n",
    "#Since this value could be a float, we will convert it to tf.int64\n",
    "\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)\n",
    "num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d5b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label): #Writing down a function to scale the data of 0 to 255 to 0 to 1.\n",
    "    image = tf.cast(image,tf.float64) #Just making sure the number is a float and not an integer.\n",
    "    image = image/255.00 #Important to give .00 after 255 to make it a flaot.\n",
    "    return image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71f1158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_and_validation_data = mnist_train.map(scale) #This will run the scale function through the dataset...\n",
    "#and store them in the following.\n",
    "scaled_train_and_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4af4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly scaling the the test data as well.\n",
    "test_data = mnist_test.map(scale)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95626766",
   "metadata": {},
   "source": [
    "### Shuffling the train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1a1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000 #This will be the size of one batch that will be shuffled at a time.\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "#The below code will create validation_data with the correct size. Using : '.take()' method.\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "#For selecting for train data, we drop the rest of validation. Using : '.skip()' method.\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples) #Since, the remaining will be train data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c861370",
   "metadata": {},
   "source": [
    "### Preparing data for batching since we are using SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9766a3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100 \n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)#model expects validation_data to be in batch form. \n",
    "#The entire thing is the same but just batch form of the same size. Same with test_data\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacdc34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([6000, 28, 28, 1]), TensorShape([6000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_input,validation_target = next(iter(validation_data))\n",
    "validation_input.shape, validation_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36894dbb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d7e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10 #Since there are 10 digits to predict the value.\n",
    "hidden_layer_size = 80 #This was initially set to 50 but then I have changed to different values like 150,100 but found this...\n",
    "#as the best one beacuse this gives the val_acc and test_acc very close which means that there is overfitting of the model...\n",
    "#with respect to the validation data.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),             #Layer 1 - input \n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'), #Layer 2 - hidden\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'), #Layer 3 - hidden\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')     #Layer 4 - output\n",
    "                            ]) #Notice for the activation we ues softmax, Since we want to give probality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73feacc1",
   "metadata": {},
   "source": [
    "### Selecting optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942f0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f1371",
   "metadata": {},
   "source": [
    "## Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0963922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.3526 - accuracy: 0.8998 - val_loss: 0.1844 - val_accuracy: 0.9462 - 2s/epoch - 3ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 1s - loss: 0.1491 - accuracy: 0.9552 - val_loss: 0.1260 - val_accuracy: 0.9627 - 862ms/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 1s - loss: 0.1071 - accuracy: 0.9679 - val_loss: 0.1055 - val_accuracy: 0.9690 - 847ms/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.0845 - accuracy: 0.9744 - val_loss: 0.0865 - val_accuracy: 0.9742 - 851ms/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.0677 - accuracy: 0.9797 - val_loss: 0.0713 - val_accuracy: 0.9765 - 835ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cb4c1e0c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_input,validation_target), verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab04cd8",
   "metadata": {},
   "source": [
    "# Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c79d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0875 - accuracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e181bee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08749296516180038"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086e2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 97.13000059127808\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy : \" + str(test_acc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a22d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f5326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
